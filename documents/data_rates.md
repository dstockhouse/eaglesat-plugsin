# Data Rate Study

Part of the process of designing the payload and subsystems to service it
involves determining what the payload requires of the subsystems beneath it
(this idea is discussed more in **requirements.md**). This document is dedicated
to a discussion of the size of data that will be produced by the Cosmic Ray
Payload while conducting science in orbit, particularly to determine what
communication requirements there exist for data rates.

It is difficult to estimate the amount of data that will be produced by the
payload because we simply don't know how much radiation that the sensor is
capable of detecting will be there to interact with it. Experiments with cameras
on the ground are difficult to extend to this application because the type of
radiation present on the ground is different from the kind we expect to see in
orbit. With these difficulties in mind, all of the estimates presented here are
merely rough estimates, entirely dependent on the amount of interacting
radiation we will see, that is, the flux of such radiation through the sensor.

### Radiation Flux

The flux of radiation through the sensor is the product of the total flux
density of radiation and the area of the sensor. We can use some dimensional
analysis to find flux through the sensor.

*flux [particles/s] = flux density [particles/m<sup>2</sup>\*s] * area [m<sup>2</sup>]*

The currently selected flight sensor will be the CMV50000, which has a sensing
area of 

*area = 41.0mm * 32.7mm = 1340.7mm<sup>2</sup> = 1.34e-3 m<sup>2</sup>*

A ballpark, perhaps best case scenario, for flux density is 1
particle/cm<sup>2</sup>\*s. That is, every square centimeter of space has on
average one particle pass through each second. If we use this value as the
expected flux density, we find the flux of particles through the sensor.

*flux = 10000 particles/m<sup>2</sup>\*s * 1.34e-3 m<sup>2</sup> = 13.4 particles/s*

This means every second we should expect to see on average 13.4 particles pass
through the sensor. Again, this is all assuming a possibly very high estimate
of radiation flux density. The current design involves 5-second exposures, so
we should expect each exposure to contain on average

*13.4 particles/s * 5 s = 67 particles*

Again, this value could be a gross overestimate. The issue is that until we know
an accurate radiation flux density, a quantity determined by the amount of
radiation in our orbit as well as physical properties of the sensor, it's
difficult to find a number we believe to be a proper estimate. 

Now, this number also assumes a static exposure time. It would be possible to
dynamically alter the exposure time to adjust the level of saturation in the
images. We could fine tune the exposure time to give us a desirable trade-off
between saturation. Lower saturation would arguably be better, to reduce risk of
event intersections or mismatching events on one sensor plane with the other,
while the constant overhead involved with finishing an exposure and reading out
the pixel data would be an increased fraction of processor usage if the sensor
spends less time sitting and collecting events. Power consumption also increases
while the sensor reads out image data and the processor computes to locate
events. The optimal saturation quantity can be determined and the sensor
programmed to seek out the exposure which maximizes the probability of this
saturation level being reached. Conceivably any saturation level could be
attained, but it is difficult to predict what the exposure time necessary for a
given saturation level would be before the spacecraft is placed into that
environment. It should also be noted that this dynamic exposure would not
strongly affect the amount of data generated by the payload. That is still
determined primarily by flux density. The only difference would be faster output
of low-volume data or slower output of higher-volume data.

### Information Encoding

The next set of variables are related to how the information is stored and
transmitted to the ground. It would be impractical to send the entire images to
the ground, two 50MP images with only 67 interesting points each would be
wasteful. Instead, there are two possibilities. 

#### Regions of Interest

The first, easier to implement but likely requiring a higher data rate, would be
to crop regions of interest from every capture to send to the ground in raw
image format. There would still be raw image data on the ground for the
physicists to use in studies, but the satellite wouldn't have to transmit entire
large images. Instead, the information sent to the ground would include:
* Timestamp of when the image was captured
* Orientation of the spacecraft during the exposure
* Exposure duration (if exposure duration is dynamic)
* Cropped regions of interest where the OBC detected candidate radiation events,
  along with location in the frame each event was found. This way the image can
be effectively recreated on the ground assuming that the space between events is
only noise.

Another estimate we need to make is how large each event appears in the frame,
that is, how many pixels are needed to store each event. Some studies on the
ground looking for radiation with an image sensor of similar pixel size show
events of approximately 12 pixels by 12 pixels, with some buffer around the
edges to ensure that all the relevant data is included. Additionally, to
properly recreate the captured frame on the ground, the location of each cropped
event on the frame must be included in the transmission. The location of the
events on the frame are represented by the pixel coordinates of some
predetermined reference point, say the top left corner of the cropped region.
The CMV50000 image sensor has a resolution of 7920x6004 pixels, so the
coordinates of any point requires 4 bytes, a negligible amount. So each event
takes up 144 pixels of raw image data at one byte per pixel, plus 4 bytes of
coordinates, and there are 67 events per capture, and there are two sensing
planes, so the amount of pixel data produced per 5-second capture is

*(144 px/event * 1 byte/px + 4 bytes/event) * 67 events/sensor * 2 sensors = 19,832 bytes = 19.4kB*

With this per-capture amount we can calculate the amount of data generated per
orbit (assuming the satellite is in a near ISS orbit).

*19.4kB/capture * 1 capture/5 seconds * 60 seconds/1 minute * 90 mintes/1 orbit = 20,916kB = 20.4MB*

This is a rough first order approximation, and there are plenty of necessary
items not considered here, so it might be acceptable to round the figure to 24MB
(192Mb). So in the worst case, the payload will produce 24MB per orbit, subject
to the above assumptions.

#### Complete Software Analysis

The second possibility would be designing software on the OBC to detect,
analyze, and characterize radiation events completely, without ever sending raw
data to the ground. This method would require complex, physics-based software
capable of detecting each radiation event present on each capture and
determining the direction of travel and energy of the particle that caused the
event. 

##### Trajectory

The software for determining the direction of origin of the particles would be
built to take advantage of the fact that two sensor planes would make it
possible to trace a line through a point on each plane and accurately determine
the trajectory if it could determine that both points were part of the same
event, and thus were made by the same particle. One immediately obvious
difficulty with this notion is that it would be difficult for anyone, including
a computer, to match each of a large number of events present on the capture to
its corresponding point on the opposite plane. One method of alleviating this
difficulty would be taking shorter exposures. This introduces increased overhead
of reading out frames instead of integrating events. Another method, which the
OBC team started considering in the fall before focusing on more pressing
matters, is using limited information about each single event on a single plane
to guess where the corresponding event lies on the other plane. A heavily
saturated image would still make it difficult to find a match, but this method
would improve the computer's ability to correctly match each point. This method
requires much more complex software to compute non-negligible image processing
on each image captured to determine where to look on the opposite plane. Since
the particle events will be of such low resolution (likely 12px by 12px), it is
not known whether the kind of image processing necessary is even possible to
execute reliably. 

Assuming all of those challenges could be overcome, we can estimate a best case
data production value for the trajectory of each event. In this case, unlike the
previous method, we are talking about tens rather than thousands of bytes. The
direction of the event can be represented by the zenith and azimuth angles
relative to some coordinate plane. This plane could be any celestial body as
long as the software and the people on the ground are in agreement. The
satellite will be able to most easily determine the angles with respect to its
own orientation, or the orientation of the sensor plane. The satellite will know
its own orientation with respect to the Earth, so either both can be sent to the
ground with the payload data or the satellite will use the relative orientation
of the event to determine the Earth-centric direction on its own. In either
case, the per-event volume of data produced will be similarly small. It would be
simplest to represent each angle with a single-precision floating-point number,
with another float for the uncertainty in the measurement, which will surely not
be negligible. So for 2 angles, 2 floats for an angle, and 4 bytes for a
float, it would take 16 bytes to represent the trajectory of each event.

##### Energy

We haven't researched enough into the physics of the situation to know if it is
even possible to reliably determine the energy of a radiation event from the
effect it has on the CMOS sensor.

If it is possible for the satellite to autonomously determine the energy of each
radiation event, the amount of data produced need only be very minimal. Similar
to the above, a single-precision floating-point number can be used to represent
the magnitude of the energy and another to represent the uncertainty in that
quantity. So 2 bytes for the energy of the event.

In the more likely case that it is infeasible to reliably calculate the event's
energy using software alone, some representation of the magnitude of the event
can be stored and sent to Earth instead. Again, the physics hasn't been fully
researched, but it seems likely that there is a signature of the energy of the
event in either the size of spread of activated pixels of the event or the
magnitude of brightness of the event pixels as a whole.

*(144 px/event * 1 byte/px + 4 bytes/event) * 67 events/sensor * 2 sensors = 19,832 bytes = 19.4kB*

With this per-capture amount we can calculate the amount of data generated per
orbit (assuming the satellite is in a near ISS orbit).

*19.4kB/capture * 1 capture/5 seconds * 60 seconds/1 minute * 90 mintes/1 orbit = 20,916kB = 20.4MB*

This is a rough first order approximation, and there are plenty of necessary
items not considered here, so it might be acceptable to round the figure to 24MB
(192Mb). So in the worst case, the payload will produce 24MB per orbit, subject
to the above assumptions.



### Capture Cadence

An implicit assumption for all of this is that the payload will be operating
constantly. This would make for the most complete collection of available data,
but also for the highest volume of data to be generated. If the volume of data
being generated is too high for the satellite to support, the payload can be
"turned off" for periods of time during the orbit. The portion of the orbit that
the payload is collecting data would be the fraction of these data volume
numbers required to be budgeted for. 

### Contact

David Stockhouse, On-Board Computer Subsystem Lead  
[stockhod@my.erau.edu](mailto:stockhod@my.erau.edu)

Connect on [Facebook](https://www.facebook.com/eaglesaterau/).

